{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65939e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # dataframes\n",
    "import numpy as np # arrays\n",
    "import re # regular expression for strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b824bcb3",
   "metadata": {},
   "source": [
    "# Case Study: How Does a Bike-Share Navigate Speedy Success?\n",
    "<img src=\"logo.png\" width=\"200\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f79554",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In 2016, <font color=blue>Cyclistic</font> launched a successful bike-share offering. \n",
    "Since then, the program has grown to a fleet of <u>5,824 bicycles</u> that are geotracked and locked into a network of <u>692 stations</u> across Chicago. \n",
    "The bikes can be unlocked from one station and returned to any other station in the system anytime.\n",
    "\n",
    "Until now, Cyclistic’s marketing strategy relied on building general awareness and appealing to broad consumer segments.\n",
    "One approach that helped make these things possible was the flexibility of its pricing plans: single-ride passes, full-day passes, and annual memberships. \n",
    "<span style='background:yellow'>Customers who purchase single-ride or full-day passes</span> are referred to as <font color=blue>casual riders</font>. \n",
    "<span style='background:yellow'>Customers who purchase annual memberships</span> are <font color=blue>Cyclistic members</font>.\n",
    "\n",
    "Cyclistic’s finance analysts have concluded that annual members are much more profitable than casual riders. \n",
    "Although the pricing flexibility helps Cyclistic attract more customers, Moreno believes that maximizing the number of annual members will be key to future growth. \n",
    "Rather than creatinga marketing campaign that targets all-new customers, Moreno believes there is a very good chance to convert casual riders into members. \n",
    "She notes that casual riders are already aware of the Cyclistic program and have chosen Cyclistic for their mobility needs.\n",
    "\n",
    "Moreno has set a clear goal: **Design marketing strategies aimed at converting casual riders into annual members**. \n",
    "In order to do that, however, the marketing analyst team needs to better understand \n",
    "\n",
    "* How do annual members and casual riders use Cyclistic bikes differently?\n",
    "* Why would casual riders buy Cyclistic annual memberships?\n",
    "* How can Cyclistic use digital media to influence casual riders to become members?\n",
    "\n",
    "Moreno and her team are interested in analyzing the Cyclistic <u>historical bike trip data</u> to identify trends.\n",
    "Here, we focus on the first question:\n",
    "\n",
    "**How do annual members and casual riders use Cyclistic bikes differently?**\n",
    "\n",
    "We are tasked to produce <font color=red>within a week</font> a report with the following deliverables:\n",
    "\n",
    "<input type=\"checkbox\" disabled  /> A clear statement of the business task\n",
    "\n",
    "<input type=\"checkbox\" disabled  /> A description of all data sources used\n",
    "\n",
    "<input type=\"checkbox\" disabled  /> Documentation of any cleaning or manipulation of data\n",
    "\n",
    "<input type=\"checkbox\" disabled  /> A summary of your analysis\n",
    "\n",
    "<input type=\"checkbox\" disabled  /> Supporting visualizations and key findings\n",
    "\n",
    "<input type=\"checkbox\" disabled  /> Your top three recommendations based on your analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434c275",
   "metadata": {},
   "source": [
    "## 1. Ask Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c3cb47",
   "metadata": {},
   "source": [
    "The ultimate **business goal** is to <u>convert casual riders into annual members</u>. To this end, we\n",
    "\n",
    "* Derive usage differences between casual riders and annual members from historical data of bike trips\n",
    "\n",
    "Subsequently, we share these insights with the marketing analytics team to find\n",
    "\n",
    "* How knowing these differences might help us convert casual riders into annual members?\n",
    "\n",
    "Finally, these insights are used to develop a marketing strategy to be presented to and approved by the executive team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b78590",
   "metadata": {},
   "source": [
    "<input type=\"checkbox\" disabled  checked/> A clear statement of the business task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd875f65",
   "metadata": {},
   "source": [
    "## 2. Prepare Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99874b9",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "\n",
    "The data to explore how different customer types are using Cyclistic bikes can be found under this [link](https://divvy-tripdata.s3.amazonaws.com/index.html). The data is public and has been made available by Motivate International Inc. under this [license](https://ride.divvybikes.com/data-license-agreement). Users' sensitive data has been excluded from the data.\n",
    "The data has been processed to remove trips that are taken by staff as they service and inspect the system; and any trips that were below 60 seconds in length (potentially false starts or users trying to re-dock a bike to ensure it was secure).\n",
    "\n",
    "In the following, we import <span style='background:yellow'>historical trip data for the year 2022</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c135a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f'2022{month+1:02d}-divvy-tripdata.csv' for month in range(12)] # csv files\n",
    "df = pd.concat(map(pd.read_csv, files), ignore_index=True) # load and merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c68ce3",
   "metadata": {},
   "source": [
    "### First glimpse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d67ebd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 5667717 and columns: 13\n",
      "ride_id                object\n",
      "rideable_type          object\n",
      "started_at             object\n",
      "ended_at               object\n",
      "start_station_name     object\n",
      "start_station_id       object\n",
      "end_station_name       object\n",
      "end_station_id         object\n",
      "start_lat             float64\n",
      "start_lng             float64\n",
      "end_lat               float64\n",
      "end_lng               float64\n",
      "member_casual          object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C2F7DD78E82EC875</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-01-13 11:59:47</td>\n",
       "      <td>2022-01-13 12:02:44</td>\n",
       "      <td>Glenwood Ave &amp; Touhy Ave</td>\n",
       "      <td>525</td>\n",
       "      <td>Clark St &amp; Touhy Ave</td>\n",
       "      <td>RP-007</td>\n",
       "      <td>42.012800</td>\n",
       "      <td>-87.665906</td>\n",
       "      <td>42.012560</td>\n",
       "      <td>-87.674367</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A6CF8980A652D272</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-01-10 08:41:56</td>\n",
       "      <td>2022-01-10 08:46:17</td>\n",
       "      <td>Glenwood Ave &amp; Touhy Ave</td>\n",
       "      <td>525</td>\n",
       "      <td>Clark St &amp; Touhy Ave</td>\n",
       "      <td>RP-007</td>\n",
       "      <td>42.012763</td>\n",
       "      <td>-87.665967</td>\n",
       "      <td>42.012560</td>\n",
       "      <td>-87.674367</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BD0F91DFF741C66D</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-25 04:53:40</td>\n",
       "      <td>2022-01-25 04:58:01</td>\n",
       "      <td>Sheffield Ave &amp; Fullerton Ave</td>\n",
       "      <td>TA1306000016</td>\n",
       "      <td>Greenview Ave &amp; Fullerton Ave</td>\n",
       "      <td>TA1307000001</td>\n",
       "      <td>41.925602</td>\n",
       "      <td>-87.653708</td>\n",
       "      <td>41.925330</td>\n",
       "      <td>-87.665800</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBB80ED419105406</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-04 00:18:04</td>\n",
       "      <td>2022-01-04 00:33:00</td>\n",
       "      <td>Clark St &amp; Bryn Mawr Ave</td>\n",
       "      <td>KA1504000151</td>\n",
       "      <td>Paulina St &amp; Montrose Ave</td>\n",
       "      <td>TA1309000021</td>\n",
       "      <td>41.983593</td>\n",
       "      <td>-87.669154</td>\n",
       "      <td>41.961507</td>\n",
       "      <td>-87.671387</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DDC963BFDDA51EEA</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-01-20 01:31:10</td>\n",
       "      <td>2022-01-20 01:37:12</td>\n",
       "      <td>Michigan Ave &amp; Jackson Blvd</td>\n",
       "      <td>TA1309000002</td>\n",
       "      <td>State St &amp; Randolph St</td>\n",
       "      <td>TA1305000029</td>\n",
       "      <td>41.877850</td>\n",
       "      <td>-87.624080</td>\n",
       "      <td>41.884621</td>\n",
       "      <td>-87.627834</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type           started_at             ended_at  \\\n",
       "0  C2F7DD78E82EC875  electric_bike  2022-01-13 11:59:47  2022-01-13 12:02:44   \n",
       "1  A6CF8980A652D272  electric_bike  2022-01-10 08:41:56  2022-01-10 08:46:17   \n",
       "2  BD0F91DFF741C66D   classic_bike  2022-01-25 04:53:40  2022-01-25 04:58:01   \n",
       "3  CBB80ED419105406   classic_bike  2022-01-04 00:18:04  2022-01-04 00:33:00   \n",
       "4  DDC963BFDDA51EEA   classic_bike  2022-01-20 01:31:10  2022-01-20 01:37:12   \n",
       "\n",
       "              start_station_name start_station_id  \\\n",
       "0       Glenwood Ave & Touhy Ave              525   \n",
       "1       Glenwood Ave & Touhy Ave              525   \n",
       "2  Sheffield Ave & Fullerton Ave     TA1306000016   \n",
       "3       Clark St & Bryn Mawr Ave     KA1504000151   \n",
       "4    Michigan Ave & Jackson Blvd     TA1309000002   \n",
       "\n",
       "                end_station_name end_station_id  start_lat  start_lng  \\\n",
       "0           Clark St & Touhy Ave         RP-007  42.012800 -87.665906   \n",
       "1           Clark St & Touhy Ave         RP-007  42.012763 -87.665967   \n",
       "2  Greenview Ave & Fullerton Ave   TA1307000001  41.925602 -87.653708   \n",
       "3      Paulina St & Montrose Ave   TA1309000021  41.983593 -87.669154   \n",
       "4         State St & Randolph St   TA1305000029  41.877850 -87.624080   \n",
       "\n",
       "     end_lat    end_lng member_casual  \n",
       "0  42.012560 -87.674367        casual  \n",
       "1  42.012560 -87.674367        casual  \n",
       "2  41.925330 -87.665800        member  \n",
       "3  41.961507 -87.671387        casual  \n",
       "4  41.884621 -87.627834        member  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n = df.shape\n",
    "print(f'Number of rows: {m} and columns: {n}')\n",
    "print(df.dtypes)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88119b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique bike types: ['electric_bike' 'classic_bike' 'docked_bike']\n",
      "Unique user types: ['casual' 'member']\n"
     ]
    }
   ],
   "source": [
    "unique_bikes = df['rideable_type'].unique()\n",
    "print(f'Unique bike types: {unique_bikes}')\n",
    "unique_users = df['member_casual'].unique()\n",
    "print(f'Unique user types: {unique_users}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ec0b47",
   "metadata": {},
   "source": [
    "### First insights\n",
    "\n",
    "Each ride has a unique identifier, the <font color=blue>ride_id</font>. It is known <font color=blue>when</font> and <font color=blue>where</font> the ride has started and ended. Furthermore, we know the <font color=blue>type of bike</font> (electric vs classic) being used as well as the <font color=blue>rider type</font> (member vs casual).\n",
    "\n",
    "* <font color=blue>ride_id</font>: 16-characters-long ride identifier (consistent across all rows?)\n",
    "* <font color=blue>rideable_type</font>: 'electric_bike' or 'classic_bike' or 'docked_bike'\n",
    "* <font color=blue>started_at, ended_at</font>: convert strings to datetime format! sort data chronologically (by started_at)!\n",
    "* <font color=blue>start_station_name || start_station_id || start_lat, start_lng</font>: start station ids (check consistency and keep one identifier)\n",
    "* <font color=blue>end_station_name || end_station_id || end_lat, start_lng</font>: end station ids (check consistency and keep one identifier)\n",
    "* <font color=blue>member_casual</font>: 'casual' or 'member'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151261d6",
   "metadata": {},
   "source": [
    "### Nulls & Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb1faacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "count_dups = df.duplicated().values.sum()\n",
    "print(f'Number of duplicated rows: {count_dups}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e13dd94",
   "metadata": {},
   "source": [
    "There are no duplicates. Many rides are missing <font color=blue>station_name</font> and <font color=blue>station_id</font> though this information can be recovered (if necessary) from geographical data <font color=blue>lat</font> and <font color=blue>lng</font>. For some rides, there is no information availible regarding the end geo location.\n",
    "\n",
    "* The data is <font color=red>reliable</font> apart for some information regarding stations which is recoverable\n",
    "* The data is <font color=red>original</font>, since it has been collected by Cyclistic itself (first-party)\n",
    "* The data is <font color=red>comprehensive</font> and contains the crucial feature <font color=blue>'member_casual'</font> to answer one of our business questions\n",
    "* The data is <font color=red>current</font>, since it contains info about the previous year\n",
    "* The data is <font color=red>cited</font> and has been promoted by google and is availible at kaggle\n",
    "\n",
    "The data ROCCCs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7812bb2",
   "metadata": {},
   "source": [
    "<input type=\"checkbox\" disabled  checked/> A description of all data sources used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d312bb0",
   "metadata": {},
   "source": [
    "## 3. Process Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a15e39",
   "metadata": {},
   "source": [
    "### 3.1 ride_id\n",
    "\n",
    "check consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a817500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many ride_ids deviate from 16 characters? Answer: 0\n"
     ]
    }
   ],
   "source": [
    "ids_len = df['ride_id'].apply(len)\n",
    "print(f'How many ride_ids deviate from 16 characters? Answer: {(ids_len != 16).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4adecef",
   "metadata": {},
   "source": [
    "### 3.2 started_at, ended_at\n",
    "\n",
    "* convert into datetime\n",
    "* calculate ride <font color=blue>duration</font>\n",
    "* extract <font color=blue>daytime</font>(morning, evening)\n",
    "* extract <font color=blue>weekday</font> (Mo,Tu,...) \n",
    "* extract <font color=blue>month</font> (Jan,Feb,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d02a880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert into datetime\n",
    "df['started_at'] = pd.to_datetime(df['started_at'])\n",
    "df['ended_at'] = pd.to_datetime(df['ended_at'])\n",
    "df = df.sort_values(by=['started_at']).reset_index() # chronological sorting just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae5dece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ride duration\n",
    "df['duration'] = df['ended_at'] - df['started_at']\n",
    "df['duration'] = df['duration'].dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e4dbc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract daytime\n",
    "def daytime(hour):\n",
    "    if (5 <= hour) and (hour < 12):\n",
    "        return \"morning\"\n",
    "    if (12 <= hour) and (hour < 17):\n",
    "        return \"noon\"\n",
    "    if (17 <= hour) and (hour < 21):\n",
    "        return \"evening\"\n",
    "    else:\n",
    "        return \"night\"\n",
    "    \n",
    "df['started_at_daytime'] = df['started_at'].dt.hour.apply(daytime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ec7c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract weekday\n",
    "df['started_at_weekday'] = df['started_at'].dt.day_name().str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73a1294",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract month\n",
    "df['started_at_month'] = df['started_at'].dt.month_name().str[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c70596",
   "metadata": {},
   "source": [
    "### 3.3 start_station, end_station\n",
    "\n",
    "A posteriori, one can state that the location data has many inconsistencies. \n",
    "Ultimately, we want a unique id for a distinct station. \n",
    "The (*lat*, *lng*)-pairs are not suitable due to fluctuations for a single location.\n",
    "The station_name is a street name and might contain several station_ids.\n",
    "The station_id should be in principle unique, though it is not.\n",
    "\n",
    "* In a first step, we need to decide what to do about missing end stations\n",
    "* In a second step, we want to identify all distinct locations by looking at the features: station_name & station_id & (lat, lng)-pairs.\n",
    "* In a third step, we want to create a dictionary for every station with an average and std of geo location, i.e., <br>\n",
    "$\\{ \\text{centroid_id}: [\\text{av_lat}, \\text{av_lng}, \\text{std_lat}, \\text{std_lng}] \\}$\n",
    "* In a fourth step, we assign for every ride_id a start_station and an end_station by geo-distance to the nearest centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeee52af",
   "metadata": {},
   "source": [
    "### step 1\n",
    "\n",
    "<u>Assumption</u>: a missing geo location for end_station most likely means that a bike has not been returned (stolen or broken). Thus, we decide to remove these entries from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "758838db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['end_lat'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d981dfe",
   "metadata": {},
   "source": [
    "### step 2\n",
    "\n",
    "We create a new dataframe 'stations' with columns (station_name, station_id, lat, lng) from both start-stations and end-stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "c37d1fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michigan Ave &amp; 8th St</td>\n",
       "      <td>623</td>\n",
       "      <td>41.872773</td>\n",
       "      <td>-87.623981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Broadway &amp; Waveland Ave</td>\n",
       "      <td>13325</td>\n",
       "      <td>41.949073</td>\n",
       "      <td>-87.648633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clark St &amp; Ida B Wells Dr</td>\n",
       "      <td>TA1305000009</td>\n",
       "      <td>41.875919</td>\n",
       "      <td>-87.631194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michigan Ave &amp; 8th St</td>\n",
       "      <td>623</td>\n",
       "      <td>41.872773</td>\n",
       "      <td>-87.623981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michigan Ave &amp; 8th St</td>\n",
       "      <td>623</td>\n",
       "      <td>41.872773</td>\n",
       "      <td>-87.623981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                station_name    station_id        lat        lng\n",
       "0      Michigan Ave & 8th St           623  41.872773 -87.623981\n",
       "1    Broadway & Waveland Ave         13325  41.949073 -87.648633\n",
       "2  Clark St & Ida B Wells Dr  TA1305000009  41.875919 -87.631194\n",
       "3      Michigan Ave & 8th St           623  41.872773 -87.623981\n",
       "4      Michigan Ave & 8th St           623  41.872773 -87.623981"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### create a dataframe containing just station names and correponding geo coordinates\n",
    "df_a = df[['start_station_name', 'start_station_id', 'start_lat', 'start_lng']]\n",
    "df_b = df[['end_station_name', 'end_station_id', 'end_lat', 'end_lng']]\n",
    "\n",
    "# common column names\n",
    "df_a = df_a.rename(lambda x: x[6:], axis='columns')\n",
    "df_b = df_b.rename(lambda x: x[4:], axis='columns')\n",
    "\n",
    "# drop nans\n",
    "df_a = df_a.dropna()\n",
    "df_b = df_b.dropna()\n",
    "\n",
    "stations = pd.concat([df_a, df_b], ignore_index=True)\n",
    "stations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "42bd3302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_id\n",
       "564             4\n",
       "570             3\n",
       "553             3\n",
       "623             3\n",
       "546             3\n",
       "               ..\n",
       "621             2\n",
       "620             2\n",
       "617             2\n",
       "615             2\n",
       "chargingstx1    2\n",
       "Name: station_name, Length: 351, dtype: int64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Does each station_id has a unique station_name?\n",
    "grouped = stations.groupby('station_id')['station_name'].unique() # rows=id and cols=list of names\n",
    "filtered = grouped[grouped.apply(lambda x: len(x) != 1)] # filter out unique mappings\n",
    "filtered.apply(len).sort_values(ascending = False) # sort by ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "79b3485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      station_id\n",
      "station_name                                    \n",
      "Bissell St & Armitage Ave - Charging           2\n",
      "Bissell St & Armitage Ave*                 25302\n",
      "                                            lat        lng\n",
      "station_name                                              \n",
      "Bissell St & Armitage Ave - Charging  41.918018 -87.652183\n",
      "Bissell St & Armitage Ave*            41.918333 -87.652194\n"
     ]
    }
   ],
   "source": [
    "### Input a check_id below to see ambiguities in station_names\n",
    "check_id = 'chargingstx1' # try out '564' '631' '13197' 'chargingstx1'\n",
    "df_grouped = stations[stations['station_id'] == check_id].groupby('station_name')\n",
    "print(df_grouped[['station_id']].count())\n",
    "print(df_grouped[['lat', 'lng']].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095641cf",
   "metadata": {},
   "source": [
    "#### comment:\n",
    "\n",
    "We have identified several ambiguities in <font color=blue>station_names</font> listed below:\n",
    "\n",
    "* **case 1**: replace a parenthesis <font color=green>' (...)'</font> with an empty string <font color=green>''</font> <br>\n",
    "e.g. Elizabeth (May) St & Fulton St $\\Rightarrow$ Elizabeth St & Fulton St\n",
    "* **case 2**: remove <font color=green>'Public Rack - '</font> from location names as it causes ambiguity <br> \n",
    "e.g. Public Rack - Spaulding Ave & Foster Ave $\\Rightarrow$ Spaulding Ave & Foster Ave\n",
    "* **case 3**: remove <font color=green>' Vaccination Site'</font> from location names as it causes ambiguity <br>\n",
    "e.g. Olive Harvey Vaccination Site $\\Rightarrow$ Olive Harvey\n",
    "* **case 4** remove <font color=green>'\\*'</font> from location names since this differentiates between charging and non-charging <br>\n",
    "e.g. Bissell St & Armitage Ave* $\\Rightarrow$ Bissell St & Armitage Ave\n",
    "* **case 5** remove <font color=green>' - Charging'</font> from location names since this differentiates between charging and non-charging <br>\n",
    "e.g. Bissell St & Armitage Ave - Charging $\\Rightarrow$ Bissell St & Armitage Ave\n",
    "* **case 6**: split names on <font color=green>' - '</font> and keep the longest split. <br>\n",
    "e.g. Lafayette Ave & 87th St - NW $\\Rightarrow$ Lafayette Ave & 87th St\n",
    "\n",
    "Subsequenly, we apply a fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1da7c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(name):\n",
    "    x = str(name)\n",
    "    \n",
    "    if '(' in x: # case 1\n",
    "        regex = r' \\(.*\\)'\n",
    "        x = re.sub(regex, '', name)   \n",
    "    if x.startswith('Public Rack - '): # case 2\n",
    "        x = x[14:]    \n",
    "    if x.endswith(' Vaccination Site'): # case 3\n",
    "        x = x[:-17]\n",
    "    if x.endswith('*'): # case 4\n",
    "        x = x[:-1]\n",
    "    if x.endswith(' - Charging'): # case 5\n",
    "        x = x[:-11]\n",
    "    \n",
    "    if ' - ' in x: # case 6\n",
    "        split = x.split(' - ')\n",
    "        return max(split, key=len)\n",
    "    return x\n",
    "\n",
    "stations['station_name'] = stations['station_name'].apply(clean)\n",
    "stations['station_id'] = stations['station_id'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c252eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "charging = stations[stations['station_id'].apply(lambda x: x.startswith('charging'))]\n",
    "charging_grouped = charging.groupby('station_id')['station_name'].unique()\n",
    "charging_dict = charging_grouped.apply(lambda x: x[0]).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "cc784163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dict_reversekeyiterator at 0x1e476a33bd0>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed(charging_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "4888644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chargingstx5\n",
      "['TA1307000138']\n",
      "chargingstx4\n",
      "['TA1306000015']\n",
      "chargingstx3\n",
      "['13053']\n",
      "chargingstx1\n",
      "['13059']\n",
      "chargingstx06\n",
      "['13332']\n",
      "chargingstx0\n",
      "['TA1306000014']\n"
     ]
    }
   ],
   "source": [
    "### problem: chargingstx0 replaces chargingstx07 which should remain fixed\n",
    "for x in reversed(charging_dict):\n",
    "    street = charging_dict[x]\n",
    "    mask1 = stations['station_name'] == street\n",
    "    mask2 = (stations['station_id'] != x) & (stations['station_id'] != street)\n",
    "    id_alt = stations[mask1 & mask2]['station_id'].unique()\n",
    "    if len(id_alt) == 1:\n",
    "        print(x)\n",
    "        print(id_alt)\n",
    "        stations['station_id'] = stations['station_id'].str.replace(x, id_alt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "20d9ac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [station_name, station_id, lat, lng]\n",
       "Index: []"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations[stations['station_id'].apply(lambda x: x.startswith('chargingstx'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "3e8dbe68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TA13060000147</th>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               station_name  lat  lng\n",
       "station_id                           \n",
       "TA13060000147           989  989  989"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations[stations['station_name'] == 'Loomis St & Lexington St'].groupby('station_id').count()\n",
    "stations[stations['station_name'] == 'Green St & Madison Ave'].groupby('station_id').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceff77c",
   "metadata": {},
   "source": [
    "#### remark:\n",
    "\n",
    "In case there are assignement errors in station_names or station_ids, some might appear unique with just a few registered rides. <br>\n",
    "\n",
    "<u>Assumption</u>: We decide to **remove a station_name or station_id** if **less than 1000 rides during the whole year** have been registered on that station. Importantly, this allows us to determine the average location for every remaining station. <br>\n",
    "\n",
    "We protocol the number of deleted stations below and apply a mask on our stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "057c4dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows removed: 142918 vs total number of rows 9592531\n"
     ]
    }
   ],
   "source": [
    "### how often does each station_name occur?\n",
    "counts = stations.groupby(['station_name'])['station_name'].count()\n",
    "counts_filter = counts.loc[lambda x : x < 1000]\n",
    "print(f'Number of rows removed: {counts_filter.sum()} vs total number of rows {counts.sum()}')\n",
    "drop_names = counts_filter.keys().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "58367b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows removed: 139367 vs total number of rows 9592531\n"
     ]
    }
   ],
   "source": [
    "### how often does each station_id occur?\n",
    "counts = stations.groupby(['station_id'])['station_id'].count()\n",
    "counts_filter = counts.loc[lambda x : x < 1000]\n",
    "print(f'Number of rows removed: {counts_filter.sum()} vs total number of rows {counts.sum()}')\n",
    "drop_ids = counts_filter.keys().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8e296a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = stations['station_name'].apply(lambda x: x not in drop_names)\n",
    "mask = stations['station_id'].apply(lambda x: x not in drop_ids)\n",
    "stations = stations[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7b3c09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Does each station_id has a unique station_name?\n",
    "grouped = stations.groupby('station_id') # rows=id and cols=list of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "000f9324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13001</th>\n",
       "      <td>41.883977</td>\n",
       "      <td>-87.624631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13006</th>\n",
       "      <td>41.882672</td>\n",
       "      <td>-87.632537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13008</th>\n",
       "      <td>41.881056</td>\n",
       "      <td>-87.624096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13011</th>\n",
       "      <td>41.879294</td>\n",
       "      <td>-87.639931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13016</th>\n",
       "      <td>41.894333</td>\n",
       "      <td>-87.622793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chargingstx06</th>\n",
       "      <td>41.872172</td>\n",
       "      <td>-87.661539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chargingstx1</th>\n",
       "      <td>41.918333</td>\n",
       "      <td>-87.652194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chargingstx3</th>\n",
       "      <td>41.883598</td>\n",
       "      <td>-87.648604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chargingstx4</th>\n",
       "      <td>41.885511</td>\n",
       "      <td>-87.652301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chargingstx5</th>\n",
       "      <td>41.943351</td>\n",
       "      <td>-87.670688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lat        lng\n",
       "station_id                         \n",
       "13001          41.883977 -87.624631\n",
       "13006          41.882672 -87.632537\n",
       "13008          41.881056 -87.624096\n",
       "13011          41.879294 -87.639931\n",
       "13016          41.894333 -87.622793\n",
       "...                  ...        ...\n",
       "chargingstx06  41.872172 -87.661539\n",
       "chargingstx1   41.918333 -87.652194\n",
       "chargingstx3   41.883598 -87.648604\n",
       "chargingstx4   41.885511 -87.652301\n",
       "chargingstx5   41.943351 -87.670688\n",
       "\n",
       "[558 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped[['lat', 'lng']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2a669f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_name\n",
       "Bissell St & Armitage Ave     2\n",
       "Green St & Randolph St        2\n",
       "Lincoln Ave & Roscoe St       2\n",
       "Loomis St & Lexington St      2\n",
       "Morgan St & Lake St           2\n",
       "Wilton Ave & Diversey Pkwy    2\n",
       "Name: station_id, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Does each station_id has a unique station_name?\n",
    "grouped = stations.groupby('station_name')['station_id'].unique() # rows=id and cols=list of names\n",
    "filtered = grouped[grouped.apply(lambda x: len(x) != 1)] # filter out unique mappings\n",
    "filtered.apply(len).sort_values(ascending = False) # sort by ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e69c7b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bissell St & Armitage Ave\n",
      "              station_name\n",
      "station_id                \n",
      "13059                13715\n",
      "chargingstx1         25304\n",
      "                    lat        lng\n",
      "station_id                        \n",
      "13059         41.918002 -87.652169\n",
      "chargingstx1  41.918333 -87.652194\n",
      "                   lat       lng\n",
      "station_id                      \n",
      "13059         0.000045  0.000038\n",
      "chargingstx1  0.000618  0.000503\n",
      "_____________\n",
      "Green St & Randolph St\n",
      "              station_name\n",
      "station_id                \n",
      "13053                 9483\n",
      "chargingstx3         22039\n",
      "                    lat        lng\n",
      "station_id                        \n",
      "13053         41.883207 -87.648747\n",
      "chargingstx3  41.883598 -87.648604\n",
      "                   lat       lng\n",
      "station_id                      \n",
      "13053         0.000999  0.001003\n",
      "chargingstx3  0.000259  0.000077\n",
      "_____________\n",
      "Lincoln Ave & Roscoe St\n",
      "              station_name\n",
      "station_id                \n",
      "TA1307000138          6996\n",
      "chargingstx5         14746\n",
      "                    lat        lng\n",
      "station_id                        \n",
      "TA1307000138  41.943794 -87.671257\n",
      "chargingstx5  41.943351 -87.670688\n",
      "                   lat       lng\n",
      "station_id                      \n",
      "TA1307000138  0.000259  0.000810\n",
      "chargingstx5  0.000450  0.000594\n",
      "_____________\n",
      "Loomis St & Lexington St\n",
      "               station_name\n",
      "station_id                 \n",
      "13332                 43837\n",
      "chargingstx06          1102\n",
      "                     lat        lng\n",
      "station_id                         \n",
      "13332          41.872192 -87.661482\n",
      "chargingstx06  41.872172 -87.661539\n",
      "                    lat       lng\n",
      "station_id                       \n",
      "13332          0.000102  0.000269\n",
      "chargingstx06  0.000015  0.000032\n",
      "_____________\n",
      "Morgan St & Lake St\n",
      "              station_name\n",
      "station_id                \n",
      "TA1306000015         19549\n",
      "chargingstx4         11725\n",
      "                    lat        lng\n",
      "station_id                        \n",
      "TA1306000015  41.885794 -87.651033\n",
      "chargingstx4  41.885511 -87.652301\n",
      "                   lat       lng\n",
      "station_id                      \n",
      "TA1306000015  0.000041  0.000031\n",
      "chargingstx4  0.001095  0.000410\n",
      "_____________\n",
      "Wilton Ave & Diversey Pkwy\n",
      "              station_name\n",
      "station_id                \n",
      "TA1306000014         34802\n",
      "chargingstx0          5158\n",
      "                    lat        lng\n",
      "station_id                        \n",
      "TA1306000014  41.932419 -87.652704\n",
      "chargingstx0  41.932422 -87.652711\n",
      "                   lat       lng\n",
      "station_id                      \n",
      "TA1306000014  0.000413  0.000351\n",
      "chargingstx0  0.000034  0.000052\n",
      "_____________\n"
     ]
    }
   ],
   "source": [
    "### Input a check_id below to see ambiguities in station_names\n",
    "for x in filtered.keys().values:\n",
    "    check_name = x # try out'564' '631' '13197' 'chargingstx1'\n",
    "    df_grouped = stations[stations['station_name'] == check_name].groupby('station_id')\n",
    "    print(x)\n",
    "    print(df_grouped[['station_name']].count())\n",
    "    print(df_grouped[['lat', 'lng']].mean())\n",
    "    print(df_grouped[['lat', 'lng']].std())\n",
    "    print('_____________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cf8611f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_id\n",
       "chargingstx0     [Wilton Ave & Diversey Pkwy]\n",
       "chargingstx06      [Loomis St & Lexington St]\n",
       "chargingstx1      [Bissell St & Armitage Ave]\n",
       "chargingstx3         [Green St & Randolph St]\n",
       "chargingstx4            [Morgan St & Lake St]\n",
       "chargingstx5        [Lincoln Ave & Roscoe St]\n",
       "Name: station_name, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations[stations['station_id'].apply(lambda x: x.startswith('charging'))].groupby('station_id')['station_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f395cf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_id\n",
       "13053                                  2\n",
       "13059                                  2\n",
       "13074                                  2\n",
       "514                                    2\n",
       "517                                    2\n",
       "518                                    2\n",
       "519                                    2\n",
       "520                                    2\n",
       "523                                    2\n",
       "546                                    2\n",
       "549                                    2\n",
       "644                                    2\n",
       "Hubbard Bike-checking (LBS-WH-TEST)    2\n",
       "TA1306000015                           2\n",
       "TA1307000138                           2\n",
       "Name: station_name, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Does each station_id has a unique station_name?\n",
    "grouped = stations.groupby('station_id')['station_name'].unique() # rows=id and cols=list of names\n",
    "filtered = grouped[grouped.apply(lambda x: len(x) != 1)] # filter out unique mappings\n",
    "filtered.apply(len).sort_values(ascending = False) # sort by ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8a2874ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             station_id\n",
      "station_name                           \n",
      "Laramie Ave & Fullerton Ave         239\n",
      "Marshfield Ave & 44th St            804\n",
      "                                   lat        lng\n",
      "station_name                                     \n",
      "Laramie Ave & Fullerton Ave  41.920000 -87.760000\n",
      "Marshfield Ave & 44th St     41.814002 -87.666603\n"
     ]
    }
   ],
   "source": [
    "### Input a check_id below to see ambiguities in station_names\n",
    "check_id = '549' # try out'564' '631' '13197' 'chargingstx1'\n",
    "df_grouped = stations[stations['station_id'] == check_id].groupby('station_name')\n",
    "print(df_grouped[['station_id']].count())\n",
    "print(df_grouped[['lat', 'lng']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0cc13c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13053\n",
      "                            station_id\n",
      "station_name                          \n",
      "Green St & Randolph St            9483\n",
      "Green St & Washington Blvd        7678\n",
      "                                  lat        lng\n",
      "station_name                                    \n",
      "Green St & Randolph St      41.883207 -87.648747\n",
      "Green St & Washington Blvd  41.883181 -87.648748\n",
      "                                 lat       lng\n",
      "station_name                                  \n",
      "Green St & Randolph St      0.000999  0.001003\n",
      "Green St & Washington Blvd  0.001026  0.000869\n",
      "_____________\n",
      "13059\n",
      "                           station_id\n",
      "station_name                         \n",
      "Bissell St & Armitage Ave       13715\n",
      "Sheridan Rd & Argyle St          7119\n",
      "                                 lat        lng\n",
      "station_name                                   \n",
      "Bissell St & Armitage Ave  41.918002 -87.652169\n",
      "Sheridan Rd & Argyle St    41.973278 -87.654736\n",
      "                                lat       lng\n",
      "station_name                                 \n",
      "Bissell St & Armitage Ave  0.000045  0.000038\n",
      "Sheridan Rd & Argyle St    0.000887  0.000201\n",
      "_____________\n",
      "13074\n",
      "                       station_id\n",
      "station_name                     \n",
      "Broadway & Wilson           18848\n",
      "Broadway & Wilson Ave        4560\n",
      "                             lat        lng\n",
      "station_name                               \n",
      "Broadway & Wilson      41.965215 -87.658185\n",
      "Broadway & Wilson Ave  41.965214 -87.658198\n",
      "                            lat       lng\n",
      "station_name                             \n",
      "Broadway & Wilson      0.000029  0.000181\n",
      "Broadway & Wilson Ave  0.000031  0.000099\n",
      "_____________\n",
      "514\n",
      "                        station_id\n",
      "station_name                      \n",
      "Hamlin Ave & Grand Ave         237\n",
      "Ridge Blvd & Howard St        1697\n",
      "                              lat        lng\n",
      "station_name                                \n",
      "Hamlin Ave & Grand Ave  41.900000 -87.720000\n",
      "Ridge Blvd & Howard St  42.019271 -87.684525\n",
      "                             lat       lng\n",
      "station_name                              \n",
      "Hamlin Ave & Grand Ave  0.000000  0.000000\n",
      "Ridge Blvd & Howard St  0.000022  0.000035\n",
      "_____________\n",
      "517\n",
      "                           station_id\n",
      "station_name                         \n",
      "Clark St & Jarvis Ave            2326\n",
      "Pulaski Rd & Armitage Ave         664\n",
      "                                 lat        lng\n",
      "station_name                                   \n",
      "Clark St & Jarvis Ave      42.015965 -87.675003\n",
      "Pulaski Rd & Armitage Ave  41.920000 -87.730000\n",
      "                                lat       lng\n",
      "station_name                                 \n",
      "Clark St & Jarvis Ave      0.000013  0.000017\n",
      "Pulaski Rd & Armitage Ave  0.000000  0.000000\n",
      "_____________\n",
      "518\n",
      "                           station_id\n",
      "station_name                         \n",
      "Conservatory Dr & Lake St        1814\n",
      "Keystone Ave & North Ave          402\n",
      "                                 lat        lng\n",
      "station_name                                   \n",
      "Conservatory Dr & Lake St  41.885498 -87.716862\n",
      "Keystone Ave & North Ave   41.910000 -87.730000\n",
      "                                lat       lng\n",
      "station_name                                 \n",
      "Conservatory Dr & Lake St  0.000018  0.000014\n",
      "Keystone Ave & North Ave   0.000000  0.000000\n",
      "_____________\n",
      "519\n",
      "                         station_id\n",
      "station_name                       \n",
      "Kostner Ave & North Ave         111\n",
      "Wolcott Ave & Fargo Ave        1172\n",
      "                               lat        lng\n",
      "station_name                                 \n",
      "Kostner Ave & North Ave  41.910000 -87.740000\n",
      "Wolcott Ave & Fargo Ave  42.016964 -87.677728\n",
      "                             lat       lng\n",
      "station_name                              \n",
      "Kostner Ave & North Ave  0.00000  0.000000\n",
      "Wolcott Ave & Fargo Ave  0.00003  0.000031\n",
      "_____________\n",
      "520\n",
      "                            station_id\n",
      "station_name                          \n",
      "Greenview Ave & Jarvis Ave        6990\n",
      "Karlov Ave & Kamerling Ave         250\n",
      "                                  lat        lng\n",
      "station_name                                    \n",
      "Greenview Ave & Jarvis Ave  42.015966 -87.668581\n",
      "Karlov Ave & Kamerling Ave  41.910000 -87.730000\n",
      "                                 lat       lng\n",
      "station_name                                  \n",
      "Greenview Ave & Jarvis Ave  0.000016  0.000033\n",
      "Karlov Ave & Kamerling Ave  0.000000  0.000000\n",
      "_____________\n",
      "523\n",
      "                           station_id\n",
      "station_name                         \n",
      "Eastlake Ter & Howard St          537\n",
      "Eastlake Ter & Rogers Ave        3928\n",
      "                                 lat        lng\n",
      "station_name                                   \n",
      "Eastlake Ter & Howard St   42.019198 -87.664313\n",
      "Eastlake Ter & Rogers Ave  42.020807 -87.665022\n",
      "                                lat       lng\n",
      "station_name                                 \n",
      "Eastlake Ter & Howard St   0.000018  0.000031\n",
      "Eastlake Ter & Rogers Ave  0.000389  0.000182\n",
      "_____________\n",
      "546\n",
      "                             station_id\n",
      "station_name                           \n",
      "Cicero Ave & Wellington Ave         273\n",
      "Damen Ave & Pershing Rd             953\n",
      "                                   lat        lng\n",
      "station_name                                     \n",
      "Cicero Ave & Wellington Ave  41.940000 -87.750000\n",
      "Damen Ave & Pershing Rd      41.823148 -87.676646\n",
      "                                  lat       lng\n",
      "station_name                                   \n",
      "Cicero Ave & Wellington Ave  0.000000  0.000000\n",
      "Damen Ave & Pershing Rd      0.001381  0.001263\n",
      "_____________\n",
      "549\n",
      "                             station_id\n",
      "station_name                           \n",
      "Laramie Ave & Fullerton Ave         239\n",
      "Marshfield Ave & 44th St            804\n",
      "                                   lat        lng\n",
      "station_name                                     \n",
      "Laramie Ave & Fullerton Ave  41.920000 -87.760000\n",
      "Marshfield Ave & 44th St     41.814002 -87.666603\n",
      "                                  lat      lng\n",
      "station_name                                  \n",
      "Laramie Ave & Fullerton Ave  0.000000  0.00000\n",
      "Marshfield Ave & 44th St     0.000017  0.00003\n",
      "_____________\n",
      "644\n",
      "                           station_id\n",
      "station_name                         \n",
      "Wabash Ave & 87th St               44\n",
      "Western Ave & Fillmore St       11801\n",
      "                                 lat        lng\n",
      "station_name                                   \n",
      "Wabash Ave & 87th St       41.740000 -87.620000\n",
      "Western Ave & Fillmore St  41.868581 -87.686239\n",
      "                                lat       lng\n",
      "station_name                                 \n",
      "Wabash Ave & 87th St       0.000000  0.000000\n",
      "Western Ave & Fillmore St  0.000048  0.000489\n",
      "_____________\n",
      "Hubbard Bike-checking (LBS-WH-TEST)\n",
      "                          station_id\n",
      "station_name                        \n",
      "2132 W Hubbard                  1542\n",
      "2132 W Hubbard Warehouse         700\n",
      "                                lat        lng\n",
      "station_name                                  \n",
      "2132 W Hubbard            41.896481 -87.689383\n",
      "2132 W Hubbard Warehouse  41.882087 -87.705530\n",
      "                               lat       lng\n",
      "station_name                                \n",
      "2132 W Hubbard            0.056466  0.038494\n",
      "2132 W Hubbard Warehouse  0.061730  0.045468\n",
      "_____________\n",
      "TA1306000015\n",
      "                       station_id\n",
      "station_name                     \n",
      "Morgan St & Lake St         19549\n",
      "Sangamon St & Lake St       17086\n",
      "                             lat        lng\n",
      "station_name                               \n",
      "Morgan St & Lake St    41.885794 -87.651033\n",
      "Sangamon St & Lake St  41.885794 -87.651040\n",
      "                            lat       lng\n",
      "station_name                             \n",
      "Morgan St & Lake St    0.000041  0.000031\n",
      "Sangamon St & Lake St  0.001300  0.000400\n",
      "_____________\n",
      "TA1307000138\n",
      "                         station_id\n",
      "station_name                       \n",
      "Lincoln Ave & Roscoe St        6996\n",
      "Wood St & Webster Ave          2328\n",
      "                               lat        lng\n",
      "station_name                                 \n",
      "Lincoln Ave & Roscoe St  41.943794 -87.671257\n",
      "Wood St & Webster Ave    41.921059 -87.672799\n",
      "                              lat       lng\n",
      "station_name                               \n",
      "Lincoln Ave & Roscoe St  0.000259  0.000810\n",
      "Wood St & Webster Ave    0.000478  0.000182\n",
      "_____________\n"
     ]
    }
   ],
   "source": [
    "### Input a check_id below to see ambiguities in station_names\n",
    "for x in filtered.keys().values:\n",
    "    check_id = x # try out'564' '631' '13197' 'chargingstx1'\n",
    "    df_grouped = stations[stations['station_id'] == check_id].groupby('station_name')\n",
    "    print(x)\n",
    "    print(df_grouped[['station_id']].count())\n",
    "    print(df_grouped[['lat', 'lng']].mean())\n",
    "    print(df_grouped[['lat', 'lng']].std())\n",
    "    print('_____________')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85aa152",
   "metadata": {},
   "source": [
    "Haversine formula to calculate distances between GPS coordiantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d48b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp[['start_lat', 'start_lng']].mean()\n",
    "df_temp[['start_lat', 'start_lng']].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a19e4d",
   "metadata": {},
   "source": [
    "<input type=\"checkbox\" disabled  checked/> Documentation of any cleaning or manipulation of data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
